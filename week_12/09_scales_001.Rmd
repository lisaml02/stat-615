---
title: "Scale / Multicollinearity Notes"
author: "David Gerard"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(broom)
earnings <- read_csv("https://dcgerard.github.io/stat_415_615/data/earnings.csv")
earnings <- mutate(earnings, log_earn = log(earn))
earnings <- filter(earnings, is.finite(log_earn))
ggplot(data = earnings, mapping = aes(x = height, y = log_earn)) +
  geom_point()

lm_earn <- lm(log_earn ~ height, data = earnings)
tidy(lm_earn)

glance(lm_earn)


## Scales
earnings <- mutate(earnings,
                   height_mm = height * 25.4,
                   height_in = height,
                   height_mi = height / 63360)

tidy(lm(log_earn ~ height_mm, data = earnings))
tidy(lm(log_earn ~ height_in, data = earnings))
tidy(lm(log_earn ~ height_mi, data = earnings))


ggplot(earnings, aes(x = height_mm, y = log_earn)) +
  geom_point()

ggplot(earnings, aes(x = height_in, y = log_earn)) +
  geom_point()

ggplot(earnings, aes(x = height_mi, y = log_earn)) +
  geom_point()


library(Sleuth3)
data("ex0823")
wine <- ex0823
ggplot(data = wine, mapping = aes(x = Wine, y = Mortality)) +
  geom_point()

wine <- mutate(wine, 
               log_wine = log(Wine),
               log_mort = log(Mortality))
lm_wine <- lm(log_mort ~ log_wine, data = wine)
tidy(lm_wine)

1.5^-0.356 - 1
```

Counties that drink 50% more wine have 13.44% lower mortality rates on average

```{r}
mile <- read_csv("https://dcgerard.github.io/stat_415_615/data/mile.csv")
glimpse(mile)
sd(mile$year / 10)

mile <- mutate(mile, decade = year / 10)
tidy(lm(seconds ~ decade, data = mile))
```

Each decade saw about a 3.93 second improvement on the mile world record on average


Create z-scores for our earnings variables
```{r}
earnings <- mutate(earnings, 
                   height_z = (height - mean(height)) / sd(height))

lm_earn_z <- lm(log_earn ~ height_z, data = earnings)
tidy(lm_earn_z)
```

Individuals that are 1 SD higher in height make about exp(0.221) times as much money, on average.

Changing the scale of the variables has no effects on the association between them.

Changing scale is just used to guide interpretation on effect sizes

# Multicollinearity

```{r}
body <- read_csv("https://dcgerard.github.io/stat_415_615/data/body.csv")
glimpse(body)
```

```{r}
cor(body)
```

```{r}
glance(lm(midarm ~ triceps, data = body))$r.squared
glance(lm(midarm ~ thigh, data = body))$r.squared
glance(lm(midarm ~ triceps + thigh, data = body))$r.squared
```

It is insufficient to just look at marginal associations to detect multicollinearity. Need to use variance inflation factors (chapter 10).



# No multicollinearity
```{r}
crew <- tibble::tribble(
  ~size, ~bonus, ~productivity,
      4,      2,            42,
      4,      2,            39,
      4,      3,            48,
      4,      3,            51,
      6,      2,            49,
      6,      2,            53,
      6,      3,            61,
      6,      3,            60
  )
```


```{r}
cor(crew)
```

```{r}
lm_size <- lm(productivity ~ size, data = crew)
lm_bonus <- lm(productivity ~ bonus, data = crew)
lm_both <- lm(productivity ~ size + bonus, data = crew)
```

```{r}
tidy(lm_size)
```

```{r}
tidy(lm_bonus)
```


```{r}
tidy(lm_both)
```


If the correlation between all variables is exactly 0, then you have the same betahats no matter what variables are in the model

You have SSR(X1) = SSR(X1|X2)
```{r}
library(car)
Anova(lm_both)
```

```{r}
Anova(lm_size)
```

```{r}
Anova(lm_bonus)
```

The amount of variation explained by a variable is the same no matter what other variables are in the model


# Including Quadratic Terms

```{r}
library(tidyverse)
library(broom)
muscle <- read_csv("https://dcgerard.github.io/stat_415_615/data/muscle.csv")
glimpse(muscle)
```

```{r}
ggplot(muscle, aes(x = age, y = mass)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```


```{r}
lm_lin <- lm(mass ~ age, data = muscle)
aout_lin <- augment(lm_lin)
ggplot(aout_lin, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```


If you see curvature, one way to account for it is to include a quadratic term.

First create the quadratic variable via mutate
```{r}
muscle <- mutate(muscle, age2 = age^2)
```
Then fit the linear model with the new variable as well as the old one.
```{r}
lm_quad <- lm(mass ~ age + age2, data = muscle)
tidy(lm_quad)
```

p-value = 0.081 (so very weak evidence of a quadratic term)

Another way to fit a quadratic term (without a prior transformation)

```{r}
lm_quad2 <- lm(mass ~ age + I(age^2), data = muscle)

## This won't work
lm(mass ~ age + age^2, data = muscle)
```

The benefit of the I approach is that you don't need to transform to make predictions. E.g., let's predict the muscle mass of a woman at age 70.


```{r}
newdf <- data.frame(age = 70, age2 = 70^2)
predict(lm_quad, newdata = newdf)
```

```{r}
newdf <- data.frame(age = 70)
predict(lm_quad2, newdata = newdf)
```

Never fit the model
```{r}
lm(mass ~ age2, data = muscle) |>
  tidy()
```







