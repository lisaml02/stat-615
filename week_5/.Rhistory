# method 1:
Vector1[is.na(Vector1)]
# method 1:
Vector1[is.na(Vector1)]
# method 2:
Vector1[!is.na(Vector1)]
str[Vector1(3)]
str[myList(3)]
str(myList[(3)])
str(myList[1:3])
myList[1:3]
myList$3
myList$"pear"
myList2 <- list(TRUE, 12.35, b= "pear", 48, c = 3:8, list(23, "team"))
myList2 <- list(TRUE, 12.35, b= "pear", 48, c = 3:8, list(23, "team"))
myList2$b
quadratic <- function(a,b,c) {
discriminant <- b^2 - 4 * a * c
if (discriminant < 0) {
return("no real roots")
} else {
root1 <- (-b + sqrt(discriminant)) / (2 * a)
root2 <- (-b - sqrt(discriminant)) / (2 * a)
return(c(root1, root2))
}
}
quadratic(1, -3, -28)
quadratic(1, 1, -30)
quadratic(3, 14, 8)
quadratic(2, 11, 6)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
hibbs <- read_csv("https://dcgerard.github.io/stat_415_615/data/hibbs.csv")
lmhibbs <- lm(vote ~ growth, data = hibbs)
t_hibbs <- tidy(lmhibbs)
t_hibbs
n <- nrow(hibbs)
2 * pt(q = -abs(4.396), df = n - 2)
data(mtcars)
lm_cars <- lm(mpg ~ drat, mtcars)
summary(lm_cars)
alpha <- 0.05
n <- 10
qt(alpha / 2, n - 2)
qt(1 - alpha / 2, n - 2)
hibbs <- read_csv("https://dcgerard.github.io/stat_415_615/data/hibbs.csv")
lmhibbs <- lm(vote ~ growth, data = hibbs)
t_hibbs <- tidy(lmhibbs, conf.int = TRUE)
select(t_hibbs, term, estimate, p.value, conf.low, conf.high)
t_hibbs <- tidy(lmhibbs, conf.int = TRUE, conf.level = 0.99)
select(t_hibbs, term, estimate, p.value, conf.low, conf.high)
library(ggplot2)
# Generate values for alpha from 0.01 to 0.1
alpha_values <- seq(0.01, 0.1, length.out = 100)
# Degrees of freedom
df <- 10
# Calculate qt(1 - alpha, df) for each alpha value
t_values <- qt(1 - alpha_values, df)
# Create a data frame
data <- data.frame(alpha = alpha_values, t_value = t_values)
# Plot
ggplot(data, aes(x = alpha, y = t_value)) +
geom_line(color = "blue", size = 1) +
labs(title = "qt(1 - alpha, 10) vs. alpha",
x = "Alpha",
y = "qt(1 - alpha, 10)") +
theme_minimal()
lm_cars <- lm(mpg ~ drat, mtcars)
t_cars <- tidy(lm_cars, conf.int = TRUE)
select(t_cars, term, estimate, p.value, conf.lo w, conf.high)
lm_cars <- lm(mpg ~ drat, mtcars)
t_cars <- tidy(lm_cars, conf.int = TRUE)
select(t_cars, term, estimate, p.value, conf.low, conf.high)
lmhibbs <- lm(vote ~ growth, data = hibbs)
newdf <- data.frame(growth = c(1.2, 2.4))
predict(object = lmhibbs, newdata = newdf, interval = "confidence") %>%
cbind(newdf)
predict(object = lmhibbs, newdata = newdf, interval = "confidence", level = 0.99) %>%
cbind(newdf)
lmhibbs <- lm(vote ~ growth, data = hibbs)
newdf <- data.frame(growth = c(1.2, 2.4))
predict(object = lmhibbs, newdata = newdf, interval = "prediction") %>%
cbind(newdf)
predict(object = lmhibbs, newdata = newdf, interval = "prediction", level = 0.99) %>%
cbind(newdf)
#' Working-Hotelling bands for simple linear regression.
#'
#' Intervals of the form "fit +/- w * standard-error", where w^2 is
#' found by \code{p * qf(level, p, n - p)}.
#'
#' @param object An object of class "lm".
#' @param newdata A data frame containing the new data.
#' @param level The confidence level of the band.
#'
#' @author David Gerard
whbands <- function(object, newdata, level = 0.95) {
stopifnot(inherits(object, "lm"))
stopifnot(inherits(newdata, "data.frame"))
stopifnot(is.numeric(level), length(level) == 1)
pout <- stats::predict(object = object,
newdata = newdata,
se.fit = TRUE,
interval = "none")
n <- nrow(stats::model.matrix(object))
p <- ncol(stats::model.matrix(object))
w <- sqrt(p * stats::qf(p = level, df1 = p, df2 = n - p))
lwr <- pout$fit - w * pout$se.fit
upr <- pout$fit + w * pout$se.fit
pout$fit <- cbind(fit = pout$fit, lwr = lwr, upr = upr)
return(pout)
}
lmhibbs <- lm(vote ~ growth, data = hibbs)
newdf <- data.frame(growth = seq(from = min(hibbs$growth),
to = max(hibbs$growth),
length.out = 100))
whfit <- whbands(object = lmhibbs, newdata = newdf)
whfit$fit %>%
cbind(newdf) ->
newdf
ggplot() +
geom_point(data = hibbs, mapping = aes(x = growth, y = vote)) +
geom_line(data = newdf, mapping = aes(x = growth, y = lwr)) +
geom_line(data = newdf, mapping = aes(x = growth, y = upr))
lmhibbs <- lm(vote ~ growth, data = hibbs)
aout <- augment(lmhibbs)
sse_full <- sum(aout$.resid^2)
ybar <- mean(hibbs$vote)
sse_reduced <- sum((aout$vote - ybar)^2)
n <- nrow(hibbs)
df_r <- n - 1
df_f <- n - 2
f_star <- ((sse_reduced - sse_full) / (df_r - df_f)) / (sse_full / df_f)
f_star
pf(q = f_star, df1 = 1, df2 = n - 2, lower.tail = FALSE)
tidy(lmhibbs)$p.value[[2]]
library(car)
Anova(mod = lmhibbs)
198.27/14
linearHypothesis(model = lmhibbs, "growth = 0")
linearHypothesis(model = lmhibbs, hypothesis.matrix = "growth = 2")
glance(lmhibbs)
knitr::opts_chunk$set(echo = TRUE)
0.997/0.111
0.997 + 1.96 * 0.111
0.997 - 1.96 * 0.111
library(tidyverse)
library(Sleuth3)
install.packages("Sleuth3")
library(tidyverse)
library(Sleuth3)
data("ex0727")
wheat <- ex0727
glimpse(wheat)
lmout <- lm(Mass ~ Tcell, data = wheat)
ggplot(wheat, aes(x = Tcell, y = Mass)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
library(broom)
t_out <- tidy(lmout)
t_out
t_out <- tidy(lmout, conf.int = TRUE)
select(t_out, term, estimate, p.value, conf.low, conf.high)
3.91127 + (10.16512 * 0.35)
7.469062 * 1.96(3.295768)
7.469062 + 1.96 * 3.295768
7.469062 - 1.96 * 3.295768
3.91127 + (10.16512 * 0.2)
3.91127 + (10.16512 * 20)
knitr::opts_chunk$set(echo = TRUE)
bank <- tibble::tribble(~gift, ~accounts,
125, 160,
100, 112,
200, 124,
75,  28,
150, 152,
175, 156,
75,  42,
175, 124,
125, 150,
200, 104,
100, 136
)
ggplot(bank, aes(x = gift, y = accounts)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
library(tidyverse)
library(broom)
library(ggplot2)
ggplot(bank, aes(x = gift, y = accounts)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
lm_r <- lm(accounts ~ gift, data = bank)
df_full <- mutate(bank, gift_factor = as.factor(gift))
lm_f <- lm(accounts ~ gift_factor, data = df_full)
View(bank)
View(df_full)
anova(lm_r, lm_f)
data("mtcars")
ggplot(data = mtcars, mapping = aes(x = log(wt), y = mpg)) +
geom_point()
mtcars <- mutate(mtcars, log_wt = log(wt))
lm_mt <- lm(mpg ~ log_wt, data = mtcars)
tidy(lm_mt, conf.int = TRUE)
-17.09 * log(2)
-20.17 * log(2)
-14.00 * log(2)
-17.09 * log(1.5)
knitr::opts_chunk$set(echo = TRUE)
lmsol <- lm(conc ~ time, sol)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(tidyverse)
library(broom)
sol <- tribble(~conc, ~time,
0.07, 9,
0.09, 9,
0.08, 9,
0.16, 7,
0.17, 7,
0.21, 7,
0.49, 5,
0.58, 5,
0.53, 5,
1.22, 3,
1.15, 3,
1.07, 3,
2.84, 1,
2.57, 1,
3.10, 1
)
ggplot(sol, mapping = aes(x = time, y = conc)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
lmsol <- lm(conc ~ time, sol)
a_sol <- augment(lmsol)
ggplot(a_sol, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(a_sol, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
ggplot(sol, aes(x = time, y = log(conc))) +
geom_point() +
geom_smooth(method = "lm")
sol_log <- mutate(sol, conc_log = log(conc))
lmsol_log <- lm(conc_log ~ time, sol_log)
asol_log <- augment(lmsol_log)
ggplot(asol_log, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(asol_log, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
estate <- read_csv("./week_5/")
-17.09 * log(1.5)
-20.17 * log(1.5)
-5.677 * log(1.5)
-17.09 * log(1.5)
-20.17 * log(1.5)
-14.00 * log(1.5)
newdf <- data.frame(log_wt = log(3))
predict(lm_mt, newdate = newdf, interval = "prediction")
newdf <- data.frame(log_wt = log(3))
predict(lm_mt, newdata = newdf, interval = "prediction")
dc <- read_csv("https://dcgerard.github.io/stat_415_615/data/dccovid.csv")
dc <- select(dc, day, positives)
dc <- filter(dc, day <= "2020-04-01", day >= "2020-03-11")
ggplot(data = dc, mapping = aes(x = day, y = log(positives))) +
geom_point()
dc <- mutate(dc, log_positives = log(positives), day_num = as.numeric(day - day[[1]]))
lm_cov <- lm(log_positives ~ day_num, data = dc)
tidy(lm_cov, conf.int = TRUE)
exp(0.218) * 1
exp(0.218) - 1
exp(0.2049) -1
exp(0.2311)
exp(0.2049) -1
exp(0.2311) -1
exp(2 * 0.218) -1
exp(2 * 0.2049) -1
exp(2* 0.2311) -1
exp(10 * 0.218) -1
exp(10 * 0.2049) -1
exp(10* 0.2311) -1
exp(10 * 0.218)
exp(10 * 0.2049)
exp(10* 0.2311)
newdf <- data.frame(day_num = 10)
predict(object = lm_cov, newdata = newdf, interval = "prediction")
exp(4.26424)
exp(3.965443)
exp(4.76037)
exp(4.26424)
exp(3.965443)
exp(4.763037)
library(Sleuth3)
data("ex0823")
wine <- ex0823
ggplot(data = wine, mapping = aes(x = log(Wine), y = log(Mortality))) +
geom_point()
wine <- mutate(wine, log_wine = log(Wine),
log_mort = log(Mortality))
lm_wine <- lm(log_mort ~ log_wine, data = wine)
tidy(lm_wine, conf.int = TRUE)
2^0.3556 - 1 # subtract one to get difference
2^0.4678 -1
2^0.2434 -1
2^-0.3556 - 1 # subtract one to get difference
2^-0.4678 -1
2^-0.2434 -1
1.1^-0.3556 - 1
1.1^-0.4678 - 1
1.1^-0.2434 -1
range(wine$Wine)
newdf <- data.frame(Wine = 20)
newdf <- mutate(newdf, log_wine = log(Wine))
predict(object = lm_wine, newdata = newdf, interval = "prediction")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(broom)
sol <- tribble(~conc, ~time,
0.07, 9,
0.09, 9,
0.08, 9,
0.16, 7,
0.17, 7,
0.21, 7,
0.49, 5,
0.58, 5,
0.53, 5,
1.22, 3,
1.15, 3,
1.07, 3,
2.84, 1,
2.57, 1,
3.10, 1
)
ggplot(sol, aes(x = time, y = conc)) +
geom_point() +
geom_smooth(method = "lm")
ggplot(sol, aes(x = time, y = conc)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
lmsol <- lm(conc ~ time, sol)
asol <- augment(lmsol)
ggplot(asol, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(asol, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
sol_log <- mutate(sol, log_conc = log(conc))
ggplot(sol_log, aes(x = time, y = log_conc)) +
geom_point() +
geom_smooth(method = "lm", = se = FALSE)
sol_log <- mutate(sol, log_conc = log(conc))
ggplot(sol_log, aes(x = time, y = log_conc)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
lmlogsol <- lm(log_conc ~ time, sol_log)
alogsol <- augment(lmlogsol)
ggplot(alogsol, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(alogsol, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
tidy(lmlogsol, conf.int = TRUE)
exp(-0.4499)
exp(-0.4499)
exp(-0.4725)
exp(-0.4272)
knitr::opts_chunk$set(echo = TRUE)
dc <- read_csv("https://dcgerard.github.io/stat_415_615/data/dccovid.csv")
dc <- select(dc, day, positives)
dc <- filter(dc, day <= "2020-04-01", day >= "2020-03-11")
ggplot(data = dc, mapping = aes(x = day, y = log(positives))) +
geom_point()
dc <- mutate(dc, log_positives = log(positives), day_num = as.numeric(day - day[[1]]))
lm_cov <- lm(log_positives ~ day_num, data = dc)
tidy(lm_cov, conf.int = TRUE)
exp(0.218) - 1
exp(0.2049) -1
exp(0.2311) -1
est <- read_csv("../week_5/estat.csv")
setwd("~/Desktop/grad_school/spring_2024/stat-615/week_5")
est <- read_csv("../week_5/estat.csv")
est <- read_csv("../week_5/estate.csv")
ggplot(est, aes(x = area, y = price)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(broom)
sol <- tribble(~conc, ~time,
0.07, 9,
0.09, 9,
0.08, 9,
0.16, 7,
0.17, 7,
0.21, 7,
0.49, 5,
0.58, 5,
0.53, 5,
1.22, 3,
1.15, 3,
1.07, 3,
2.84, 1,
2.57, 1,
3.10, 1
)
ggplot(sol, aes(x = time, y = conc)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
lmsol <- lm(conc ~ time, sol)
asol <- augment(lmsol)
ggplot(asol, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(asol, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
sol_log <- mutate(sol, log_conc = log(conc))
ggplot(sol_log, aes(x = time, y = log_conc)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
lmlogsol <- lm(log_conc ~ time, sol_log)
alogsol <- augment(lmlogsol)
ggplot(alogsol, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(alogsol, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
tidy(lmlogsol, conf.int = TRUE)
exp(-0.4499)
exp(-0.4725)
exp(-0.4272)
est <- read_csv("../week_5/estate.csv")
ggplot(est, aes(x = area, y = price)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
lmest <- lm(price ~ area, est)
aest <- augment(lmest)
ggplot(aest, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(aest, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
ggplot(est, aes(x = log(area), y = log(price))) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
logest <- mutate(est, log_price = log(price),
log_area = log(area))
lmlogest <- lm(log_price ~ log_area, logest)
alogest <- augment(lmlogest)
ggplot(alogest, aes(x = .fitted, y = .resid)) +
geom_point() +
geom_hline(yintercept = 0)
ggplot(alogest, aes(sample = .resid)) +
geom_qq() +
geom_qq_line()
tidy(logest, conf.int = TRUE)
tidy(lmlogest, conf.int = TRUE)
2^1.255
2^1.255 -1
wine <- mutate(wine, log_wine = log(Wine),
log_mort = log(Mortality))
library(Sleuth3)
data("ex0823")
wine <- ex0823
ggplot(data = wine, mapping = aes(x = log(Wine), y = log(Mortality))) +
geom_point()
wine <- mutate(wine, log_wine = log(Wine),
log_mort = log(Mortality))
lm_wine <- lm(log_mort ~ log_wine, data = wine)
tidy(lm_wine, conf.int = TRUE)
2^-0.3556 - 1 # subtract one to get difference
2^1.255 -1
2^1.188 -1
2^1.321 -1
range(logest$log_area)
range(est$area)
newdf <- data.frame(area = 1020)
newdf <-mutate(newdf, log_area = log(area))
predict(object = lmlogest, newdata = newdf, interval = "prediction")
newdf <- data.frame(Wine = 20)
newdf <- mutate(newdf, log_wine = log(Wine))
predict(object = lm_wine, newdata = newdf, interval = "prediction")
newdf <- data.frame(area = 1020)
newdf <-mutate(newdf, log_area = log(area))
predict(object = lmlogest, newdata = newdf, interval = "prediction")
exp(11.492)
exp(11.045)
exp(11.938)
newdf_1 <- data.frame(area = 3067)
newdf_1 <-mutate(newdf, log_area = log(area))
predict(object = lmlogest, newdata = newdf_1, interval = "prediction")
newdf_1 <- data.frame(area = 3067)
newdf_1 <-mutate(newdf, log_area = log(area))
predict(object = lmlogest, newdata = newdf_1, interval = "prediction")
newdf_1 <- data.frame(area = 3067)
newdf_1 <-mutate(newdf_1, log_area = log(area))
predict(object = lmlogest, newdata = newdf_1, interval = "prediction")
exp(12.873)
exp(12.429)
exp(13.318)
