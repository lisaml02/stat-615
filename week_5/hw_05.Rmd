---
title: "hw_05"
author: "lisa liubovich"
date: "2024-02-20"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggplot2)
```

# Solution Concentration

## 1.

```{r sc}
library(tidyverse)
library(broom)
sol <- tribble(~conc, ~time,
0.07, 9,
0.09, 9,
0.08, 9,
0.16, 7,
0.17, 7,
0.21, 7,
0.49, 5,
0.58, 5,
0.53, 5,
1.22, 3,
1.15, 3,
1.07, 3,
2.84, 1,
2.57, 1,
3.10, 1
)
```

```{r sc1}
ggplot(sol, mapping = aes(x = time, y = conc)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
  
```

plot appears to be curved, which violates the linearity assumption. The vertical spread of the points seems inconsistent, which indicates non-constant variance.

```{r sc1 resid vs fitted}
lmsol <- lm(conc ~ time, sol)
a_sol <- augment(lmsol)
ggplot(a_sol, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

One section's spread is not the same as the others', so there's definitely some unequal variance happening here. Plus there seems to be a pattern, so there is potentially a lack of independence. Before we move on, let's check for normality too.

Q-Q plot:

```{r sc1 qq plot}
ggplot(a_sol, aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()
```

the points do not fall along the diagonal line very well, so this suggests the residuals may not follow a normal distribution.

## 2.

```{r sc2}
ggplot(sol, aes(x = time, y = log(conc))) +
  geom_point() +
  geom_smooth(method = "lm")
```

much better linearity and the vertical spread looks much more consistent!

```{r sc2 residuals vs fitted}
sol_log <- mutate(sol, conc_log = log(conc))
lmsol_log <- lm(conc_log ~ time, sol_log)
asol_log <- augment(lmsol_log)
ggplot(asol_log, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

The vertical spread looks MUCH more even. Independence?

Let's check for normality just to be sure:

```{r log qq plot}
ggplot(asol_log, aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()
```

A bit of right skew, but better than the non-transformed model.

COME BACK TO INTERP SECTION

# Real Estate Data

```{r loading data}
estate <- read_csv("./week_5/")
```

## Analysis:

initial plot of area vs. price:

```{r initial plot}
ggplot(estate, aes(x = area, y = price)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE)
```

relationship looks fairly linear. But the vertical spread looks inconsistent. Let's try a linear regression and look at the residuals to see if the variance is unequal.

```{r intial resid vs fitted plot}
lmest <- lm(price ~ area, estate)
aest <- augment(lmest)
ggplot(aest, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

The shape of the residuals is funnel shaped, indicating we have non-constant variance. Let's try a log transformation first to see if that makes a difference.

log-transformed plot:

```{r log- transformed plot}
est_log <- mutate(estate, log_price = log(price), log_area= log(area))
ggplot(est_log, aes(x = log_area, y = log_price)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE)
```

Definitely looks more linear and much more consistent vertical spread. Let's do another residual vs. fitted plot to confirm that the variance is constant.

```{r log-transformed resid vs fitted plot}
lmest_log <- lm(log_price ~ log_area, est_log)
aest_log <- augment(lmest_log)
ggplot(aest_log, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

Much better vertical spread, so now we have constant variance. There is no clear pattern to the plot, so we can assume independence.

COME BACK TO THIS PART ABOUT INDEPENDENCE AND NORMALITY

Let's build a prediction equation for a model:

```{r building prediction equation}
summary(lmest_log)
```

Our prediction equation is: log_price = 2.7963 + 1.25518log_area.

Both of these coefficients are statistically significant at a 0.0001 level (both less than 0.0001), indicating that it is unlikely that this association is the result of random chance alone. Let's construct a confidence interval to account for uncertainty:

```{r confidence interval}
t_lmest_log <- tidy(lmest_log, conf.int = TRUE)
select(t_lmest_log, term, estimate, p.value, conf.low, conf.high)
```

Our 95% confidence interval for log_area is 1.188891 to 1.321470. 0 is not in the confidence interval, so we have further evidence to suggest that this relationship between log_price and log_area is not a result of random chance.

Returning to our summary of the model, the F-statistic is high and has a low p-value of less than 0.001, which tells us we have a statistically significant model. Our R^2^ is 0.7263, indicating that 72.63 % of the variation in log_price is explained by log_area.

Finally, let's check for normality:

```{r}
ggplot(lmest_log, aes(sample = .resid)) +
  geom_qq() +
  geom_qq_line()
```

A bit skewed but mostly normal, especially given the large sample size of n = 522.

Now that we know this is a good model, let's try to use it to give the predictions the client wants:

```{r predictions}
predict_log_price <- function(log_area) {
  log_price <- 2.7963 + 1.25518 * log_area
  return(log_price)
}
predict_log_price(576)
predict_log_price(1020)
predict_log_price(3067)
```

```{r}
exp(725.78)
```

## Report:
